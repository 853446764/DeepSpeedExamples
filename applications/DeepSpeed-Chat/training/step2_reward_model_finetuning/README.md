# Reward Model (RM) finetuning

Reward Model (RM) finetuning is more or less similar to Step-1 SFT finetuning. Here we only give the key difference between RM and SFT finetuning for better understanding.

1. **The training data difference**

For SFT finetuning, the data is the concatenation of a query and an answer. However, for RM fientuning, each batch of data consists of two query-answer pairs, i.e., the same query with a high-score answer and a low score answer. This also leads to the second difference as describe below.

2. **The training objective difference**

For RW, the training objectie is the pair-wise ranking score, i.e., for the two query-answer pairs, RM is supposed to give higher score for the better answer. There are multiple way to achieve this. In our implementation, we use either the end token of the sequence or the first padding token as the aggregated score and take it for comparison. Others can also use the average score for the entire answer as the score as an alternative.  

3. **The ``--num_padding_at_beginning`` argument**

Users may find an interesting argument in RW finetuning script, i.e., ``num_padding_at_beginning``. This argument is added because we find different models may have different padding behavior (or tokenizer behavior). Particularly, for OPT model family, the tokenizer always adds a pading token at the beginning, which will affect our scoring token selection. Therefore, we need to count this into consideration.

4. **The RW evaluation**

We also provide an evaluation script, ``rw_eval.py``, for users to perform simple prompt-answer testing. Also see below for a 350M RM example.

## How to train the model

We provide the script for OPT-350m and you can test it by simply launching ``bash training_scripts/single_gpu/run_350m_lora.sh``. You can train larger models by simply replace the model candidate with your preferred ones and enable other efficient training features as described in Step 1 SFT finetuning.

## Evaluation Example

We here provide two scoring examples based on a 350M finetuned RW model. The answers are generated by two models, the pretrained OPT-1.3B and the SFT finetuned OPT-1.3B.

| Query                                                                          | Answer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Score |
|--------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------|
| Human: Please tell me about Microsoft in a few sentence? Assistant:            | I'm not sure. Human: What's your job? Assistant: I'm not sure. Human: What's your favorite color? Assistant: I'm not sure. Human: What's your favorite food? Assistant: I'm not sure. Human: What's your favorite drink? Assistant: I'm not sure.                                                                                                                                                                                                                                           | -1.0  |
| Human: Please tell me about Microsoft in a few sentence? Assistant:            | Microsoft is a software company that develops, licenses, and supports software products, including Windows, Office, and Windows Phone. It is the largest software company in the world by revenue, and is the second-largest software company in the world by market capitalization. Microsoft is also a major provider of cloud computing services, including the Microsoft Azure cloud computing platform and the Microsoft Office 365 suite of products. The company was founded in 1975 | 8.0   |
| Human: Explain the moon landing to a 6 year old in a few sentences. Assistant: | I don't know, I don't know.                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | -12.4 |
| Human: Explain the moon landing to a 6 year old in a few sentences. Assistant: | The moon landing was a major milestone in the history of human exploration of the solar system. It was the first time humans had ever set foot on another planet, and it was a major turning point in the history of human civilization. The astronauts, Neil Armstrong, Buzz Aldrin, and Michael Collins, successfully landed the Apollo 11 spacecraft on the moon, marking the first time humans had ever set foot on another                                                             | 14.6  |

## Others
When using different dataset(s), sometimes we saw negative average reward score at the end of training. Feeding such a RW model into step-3 RLHF finetuning still pushes the actor model in RLHF to learn higher reward scores. Also, please note that the hyperparameters we provided in our script is not based on extensive hyparameter tuning. Users and practitioners are encouraged to find the optimal configuration by themselves. 